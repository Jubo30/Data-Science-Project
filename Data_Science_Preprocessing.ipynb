{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:19:11 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: scrapybot)\n",
      "2020-11-08 15:19:11 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.19041-SP0\n",
      "2020-11-08 15:19:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "class GERdailyZuwachs(scrapy.Spider):\n",
    "    name = 'corona_gerdaily'\n",
    "    start_urls = ['https://de.wikipedia.org/wiki/COVID-19-Pandemie_in_Deutschland/Statistik']\n",
    "\n",
    "    def parse(self, response):\n",
    "        for bundesland in response.css('table.wikitable > tbody > tr'):    #.zebra.toptextcells.mw-collapsible.mw-made-collapsible\n",
    "\n",
    "                yield{\n",
    "                    \n",
    "                  'BW' : bundesland.xpath('td[2]//text()').extract_first(),\n",
    "                  'BY' : bundesland.xpath('td[3]//text()').extract_first(),\n",
    "                  'BE' : bundesland.xpath('td[4]//text()').extract_first(),\n",
    "                  'BB' : bundesland.xpath('td[5]//text()').extract_first(),\n",
    "                  'HB' : bundesland.xpath('td[6]//text()').extract_first(),\n",
    "                  'HH' : bundesland.xpath('td[7]//text()').extract_first(),\n",
    "                  'HE' : bundesland.xpath('td[8]//text()').extract_first(),\n",
    "                  'MV' : bundesland.xpath('td[9]//text()').extract_first(),\n",
    "                  'NI' : bundesland.xpath('td[10]//text()').extract_first(),\n",
    "                  'NW' : bundesland.xpath('td[11]//text()').extract_first(),\n",
    "                  'RP' : bundesland.xpath('td[12]//text()').extract_first(),\n",
    "                  'SL' : bundesland.xpath('td[13]//text()').extract_first(),\n",
    "                  'SN' : bundesland.xpath('td[14]//text()').extract_first(),\n",
    "                  'ST' : bundesland.xpath('td[15]//text()').extract_first(),\n",
    "                  'SH' : bundesland.xpath('td[16]//text()').extract_first(),\n",
    "                  'TH' : bundesland.xpath('td[17]//text()').extract_first(),\n",
    "                  'Gesamt' : bundesland.xpath('td[18]//text()').extract_first(),\n",
    "               }\n",
    "\n",
    "process = CrawlerProcess({\n",
    "'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
    "'FEED_FORMAT': 'csv',\n",
    "'FEED_URI': 'de_zuwachsneu.csv'\n",
    "})\n",
    "\n",
    "#process.crawl(GERdailyZuwachs)\n",
    "#process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "de_zuwachs = pd.read_csv('de_zuwachs4.csv', skiprows = range(1,547), nrows = 105 , thousands = '.' ) #, dtype={'BW': int } )\n",
    "de_zuwachs['Datum'] = pd.date_range(start='24/2/2020', periods=len(de_zuwachs), freq='D')\n",
    "\n",
    "#löst das Problem mit dem falschen Datum\n",
    "first_col = de_zuwachs.pop('Datum')\n",
    "de_zuwachs.insert(0, 'Datum', first_col)\n",
    "\n",
    "#Ändert die NAN und - zu 0\n",
    "de_zuwachs = de_zuwachs.fillna(0)\n",
    "de_zuwachs = de_zuwachs.replace('—',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tode = pd.read_csv('de_zuwachs.csv', skiprows = range(1,735), nrows = 93, thousands = '.') \n",
    "\n",
    "de_tode['Datum'] = pd.date_range(start='3/9/2020', periods=len(de_tode), freq='D')\n",
    "first_col = de_tode.pop('Datum')\n",
    "de_tode.insert(0, 'Datum', first_col)\n",
    "\n",
    "#Ändert die NAN und - zu 0\n",
    "de_tode = de_tode.fillna(0)\n",
    "de_tode = de_tode.replace('–',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kreise_zuwachs = pd.read_csv('COVID-19 Cases Germany_1604319250294.csv')\n",
    "kreise_zuwachs.drop(['relative_case_changes','fb_id','cases_per_population','relative_death_changes','bundesland_ags','kreis_ags','kreis_nuts','kreis_name','deaths_per_population','fb_datetime'], axis=1, inplace=True)\n",
    "kreise_zuwachs = kreise_zuwachs.fillna(0)\n",
    "kreise_zuwachs['deaths'] = kreise_zuwachs['deaths'].astype(int)\n",
    "kreise_zuwachs['publication_datetime'] = kreise_zuwachs['publication_datetime'].str[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "laendereinwohner = pd.read_csv('population-figures-by-country-csv_csv.csv')\n",
    "laendereinwohner = laendereinwohner[['Country','Year_2016']]\n",
    "laendereinwohner = laendereinwohner.fillna(0)\n",
    "laendereinwohner['Year_2016'] = laendereinwohner['Year_2016'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundeslandeinwohner = pd.read_csv('bundeslandeinw.csv',skiprows= range(1,2), nrows = 16, thousands = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kreise_zuwachs = kreise_zuwachs.sort_values(['location_label','publication_datetime'])\n",
    "kreise_zuwachs['täglicher Wachstum'] = kreise_zuwachs['cases'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "counties = pd.read_csv('covid_confirmed_usafacts.csv')\n",
    "areacounty = pd.read_excel('LND01.xls')\n",
    "pop = pd.read_csv('covid_county_population_usafacts.csv')\n",
    "\n",
    "counties = counties.drop_duplicates(subset =[\"County Name\"])\n",
    "counties = counties.drop(['stateFIPS','countyFIPS'], axis=1)\n",
    "arraycounties = [counties['County Name'].tolist()] + [counties['State'].tolist()]\n",
    "\n",
    "dfState = pd.DataFrame()\n",
    "dflistC = counties['County Name'].tolist()\n",
    "dfState = counties[['County Name','State']]\n",
    "dfState = dfState.reset_index()\n",
    "dfState = dfState.drop_duplicates(subset=['County Name'])\n",
    "dflistC = list(dict.fromkeys(dflistC))\n",
    "dic = {}\n",
    "\n",
    "for i in dflistC:\n",
    "    dic[i] = pd.DataFrame()\n",
    "\n",
    "k = 0\n",
    "avgwachstum = []\n",
    "\n",
    "for name, df in dic.items():\n",
    "        dic[name] = counties.loc[(counties['County Name'] == arraycounties[0][k]) & (counties['State'] == arraycounties[1][k])]\n",
    "        dic[name] = dic[name].reset_index()\n",
    "        dic[name] = dic[name].T\n",
    "        dic[name] = dic[name].rename(columns={0:'cases'})\n",
    "        dic[name]['County Name'] = arraycounties[0][k]\n",
    "        dic[name] = dic[name].iloc[3:]\n",
    "        dic[name] = dic[name].reset_index()\n",
    "        dic[name] = dic[name].rename(columns={'index': 'date'})\n",
    "        dic[name]['date'] = pd.to_datetime(dic[name]['date'], format='%m/%d/%y')\n",
    "        dic[name] = dic[name].loc[dic[name]['date']< '2020-06-20']\n",
    "        dic[name]['cases'] =  dic[name]['cases'].astype(int) \n",
    "        dic[name]['dailycases'] = dic[name]['cases'].diff()\n",
    "        dic[name]['dailycases'][dic[name]['dailycases'] < 0] = 0\n",
    "        dic[name]['Rate'] = dic[name]['cases'].pct_change()\n",
    "        dic[name]['Rate'] = dic[name]['Rate']*100\n",
    "        dic[name]['Rate'] = dic[name]['Rate'].replace([np.inf, -np.inf], 0)\n",
    "        dic[name] = dic[name].fillna(0)\n",
    "        avgwachstum.append(dic[name]['Rate'].sum()/len(dic[name].index))\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "areacounty = pd.read_excel('LND01.xls')\n",
    "areacounty = areacounty[['Areaname','LND010190D']]\n",
    "areacounty['Areaname'] = areacounty['Areaname'].str[:-4]\n",
    "areacounty['Areaname'] = areacounty['Areaname'] + ' County'\n",
    "areacounty = areacounty.drop_duplicates(subset =[\"Areaname\"])\n",
    "areacounty = areacounty.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {'County':dflistC,'AGR':avgwachstum}\n",
    "DFCounty = pd.DataFrame(t)\n",
    "DFCounty['State'] = dfState['State']\n",
    "DFCounty['Area'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Jedem County wird die passende Fläche zugeordnet\n",
    "for i in range(len(areacounty)):\n",
    "    for j in range(len(dflistC)):\n",
    "        if dflistC[j] == areacounty['Areaname'][i]:\n",
    "            DFCounty['Area'][j] = areacounty['LND010190D'][i]\n",
    "\n",
    "DFCounty['Area'] = DFCounty['Area'] * 2.59  #Von Meilen auf Kilometer\n",
    "DFCounty['Population'] = 0\n",
    "\n",
    "#Jedem County wird die passende Bevölkerungszahl zugeordnet\n",
    "for i in range(len(pop)):\n",
    "    for j in range(len(dflistC)):\n",
    "        if dflistC[j] == pop['County Name'][i]:\n",
    "            DFCounty['Population'][j] = pop['population'][i]\n",
    "\n",
    "#Aus Fläche und Bevölkerung wird Bevölkerungsdichte berechnet, da es diese werde nicht einfach so zum Abruf gab\n",
    "DFCounty['Density'] = DFCounty['Population'] / DFCounty['Area'] \n",
    "DFCounty=DFCounty.replace([np.inf, -np.inf], np.nan)\n",
    "DFCounty = DFCounty.fillna(0)\n",
    "DFCounty = DFCounty[DFCounty['Density'] != 0]\n",
    "DFCounty = DFCounty[DFCounty['AGR'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arraykreise = kreise_zuwachs['location_label'].tolist()\n",
    "arraykreise = list(dict.fromkeys(arraykreise))  #Entfernt alle Dubletten\n",
    "#arraykreise = ['Mettmann','Main-Taunus-Kreis','Offenbach','Esslingen','Recklinghausen','Altmarkkreis Salzwedel','Prignitz','Ostprignitz-Ruppin','Uckermark','Stendal']\n",
    "arraykreise = sorted(arraykreise)\n",
    "dflist = arraykreise\n",
    "d = {} #dict damit können alle erstelleten DataFrames aufgerufen werden\n",
    "\n",
    "for j in dflist:\n",
    "   d[j] = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "durchschnittlicheswachstum = []\n",
    "durchschnittlicheswachstumD = []\n",
    "\n",
    "for name, df in d.items():\n",
    "        d[name] = kreise_zuwachs[kreise_zuwachs['location_label'] == arraykreise[i]]\n",
    "        d[name] = d[name].drop(columns=['population','bundesland_name'])\n",
    "        d[name]['dailycases'] = d[name]['cases_per_100k'].diff()\n",
    "        d[name]['dailydeaths'] = d[name]['deaths_per_100k'].diff()\n",
    "        d[name]['publication_datetime'] = pd.to_datetime(d[name]['publication_datetime'])\n",
    "        d[name] = d[name].sort_values(['publication_datetime'])\n",
    "        d[name] = d[name].loc[d[name]['publication_datetime']< '2020-06-20']\n",
    "        d[name]['dailycases'][d[name]['dailycases'] < 0] = 0\n",
    "        d[name]['Rate'] = d[name]['cases'].pct_change()\n",
    "        d[name]['Rate'] = d[name]['Rate']*100\n",
    "        d[name]['Rate'] = d[name]['Rate'].replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        d[name]['RateD'] = d[name]['deaths'].pct_change()\n",
    "        d[name]['RateD'] = d[name]['RateD']*100\n",
    "        d[name]['RateD'] = d[name]['RateD'].replace([np.inf, -np.inf], 0)\n",
    "        d[name] = d[name].fillna(0)\n",
    "        d[name] = d[name].reset_index()\n",
    "        \n",
    "        #10 DFs sind vorhanden nun muss durchschnittliche Wachstumsrate berechnet werden\n",
    "        durchschnittlicheswachstum.append(d[name]['Rate'].sum()/len(d[name].index))\n",
    "        durchschnittlicheswachstumD.append(d[name]['RateD'].sum()/len(d[name].index))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird mithilfe eines Dictionary für jeden Landkreis ein DF erstellt und dann eine Liste in der alle Durchschnittlichen Wachstumsraten aller Landkreise drin stehen.\n",
    "\n",
    "Ich gehe davon aus. Dass wenn ein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Hochsauerlandkreis'].loc[0,'dailycases'] = d['Hochsauerlandkreis'].loc[0, 'cases_per_100k']\n",
    "d['Hochsauerlandkreis']['kumcases'] = d['Hochsauerlandkreis']['dailycases'].cumsum()\n",
    "\n",
    "d['Hochsauerlandkreis']['dailydeaths'] = d['Hochsauerlandkreis']['deaths_per_100k'].diff()\n",
    "d['Hochsauerlandkreis']['dailydeaths'][d['Hochsauerlandkreis']['dailydeaths'] < 0] = 0\n",
    "d['Hochsauerlandkreis'].loc[0,'dailydeaths'] = d['Hochsauerlandkreis'].loc[0, 'deaths']\n",
    "d['Hochsauerlandkreis']['kumdeaths'] = d['Hochsauerlandkreis']['dailydeaths'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Essen'].loc[0,'dailycases'] = d['Essen'].loc[0, 'cases_per_100k']\n",
    "d['Essen']['kumcases'] = d['Essen']['dailycases'].cumsum()\n",
    "\n",
    "d['Essen']['dailydeaths'] = d['Essen']['deaths_per_100k'].diff()\n",
    "d['Essen']['dailydeaths'][d['Essen']['dailydeaths'] < 0] = 0\n",
    "d['Essen'].loc[0,'dailydeaths'] = d['Essen'].loc[0, 'deaths_per_100k']\n",
    "d['Essen']['kumdeaths'] = d['Essen']['dailydeaths'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['Hochsauerlandkreis']['Wochentag'] = d['Hochsauerlandkreis']['publication_datetime'].dt.day_name()\n",
    "dic['Albany County']['Weekday'] = dic['Albany County']['date'].dt.day_name()\n",
    "d['Essen']['Wochentag'] = d['Essen']['publication_datetime'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German_Germany.1252'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "bundzuwachsraw = pd.read_csv('table-1.csv')\n",
    "bundzuwachsraw.set_index('Datum')\n",
    "bundzuwachsraw = bundzuwachsraw.drop(['KW','Differenz zum Vortag','Bem.','Datum'],1) \n",
    "bundzuwachsraw = bundzuwachsraw.iloc[:-1]\n",
    "bundzuwachsraw = bundzuwachsraw.fillna(0)\n",
    "bundzuwachsraw = bundzuwachsraw.replace('—',0)\n",
    "\n",
    "for column in bundzuwachsraw:\n",
    "    bundzuwachsraw[column] = bundzuwachsraw[column].astype(str)\n",
    "    bundzuwachsraw[column] = bundzuwachsraw[column].str.replace('.','')\n",
    "    for c in ascii_lowercase:\n",
    "        bundzuwachsraw[column] = bundzuwachsraw[column].str.replace(c,'')\n",
    "    bundzuwachsraw[column] = bundzuwachsraw[column].str.replace(')','')\n",
    "    bundzuwachsraw[column] = bundzuwachsraw[column].str.replace('(','')\n",
    "    bundzuwachsraw[column] = bundzuwachsraw[column].astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundzuwachs = bundzuwachsraw.diff()\n",
    "bundzuwachs.iloc[0] = bundzuwachsraw.iloc[0]\n",
    "bundzuwachsraw['Date'] = pd.date_range(start='24/2/2020', periods=len(bundzuwachsraw), freq='D')        \n",
    "bundzuwachs['Date'] = pd.date_range(start='24/2/2020', periods=len(bundzuwachsraw), freq='D')\n",
    "bundzuwachsraw = bundzuwachsraw.set_index('Date')\n",
    "bundzuwachs = bundzuwachs.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundchange = bundzuwachsraw.pct_change()\n",
    "bundchange = bundchange*100\n",
    "bundchange = bundchange.fillna(0)\n",
    "bundchange = bundchange.replace([np.inf, -np.inf], 0) # Was sollte am besten hier hin für die Wachstumsrate?\n",
    "# tägliche prozentuale Änderung der Coronazahlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundzuwachsraw_1 = bundzuwachsraw.iloc[:118] # Februar Tage + März + April + Mai + Juni bis zum 19\n",
    "bundzuwachsraw_2 = bundzuwachsraw.iloc[118:]\n",
    "bundzuwachs_1 = bundzuwachs.iloc[:118]\n",
    "bundzuwachs_2 = bundzuwachs.iloc[118:]\n",
    "bundchange_1 = bundchange.iloc[:118]\n",
    "bundchange_2 = bundchange.iloc[118:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "bundzuwachsraw_1['date'] = bundzuwachsraw_1.index\n",
    "bundzuwachsraw_1['datef'] = pd.to_datetime(bundzuwachsraw_1['date'])\n",
    "bundzuwachsraw_1['datef']=bundzuwachsraw_1['datef'].map(dt.datetime.toordinal)\n",
    "bundzuwachsraw_2['date'] = bundzuwachsraw_2.index\n",
    "bundzuwachsraw_2['datef'] = pd.to_datetime(bundzuwachsraw_2['date'])\n",
    "bundzuwachsraw_2['datef']=bundzuwachsraw_2['datef'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "bundzuwachspred = pd.DataFrame(bundzuwachsraw_2['date'])\n",
    "column = 'BY'\n",
    "\n",
    "for column in bundzuwachsraw_1:\n",
    "    y = bundzuwachsraw_1[column].to_numpy()\n",
    "    x = bundzuwachsraw_1['datef'].to_numpy()\n",
    "    xpred = bundzuwachsraw_2['datef'].to_numpy()\n",
    "    ypred = bundzuwachsraw_2[column].to_numpy()\n",
    "    x = x.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    xpred = xpred.reshape(-1, 1)\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "    predic = regr.predict(xpred)\n",
    "    bundzuwachspred[column] = predic\n",
    "bundzuwachspred = bundzuwachspred.drop(columns = ['date','datef','Gesamt'])\n",
    "bundchangepred = bundzuwachspred.pct_change()\n",
    "bundchangepred = bundchangepred*100\n",
    "bundchangepred = bundchangepred.fillna(0)\n",
    "bundchangepred = bundchangepred.replace([np.inf, -np.inf], 0)\n",
    "bundchangepred = bundchangepred.drop(bundchangepred.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "durchschnittlichwachstum = bundchangepred.sum()/len(bundchange_1.index)\n",
    "#durchschnittlichwachstum = bundchange_1.sum()/len(bundchange_1.index)\n",
    "durchwachstumfnl = pd.DataFrame({'Bundesland':durchschnittlichwachstum.index,'AGR':durchschnittlichwachstum.values})\n",
    "#fnl = Final  AGR = average growth rate\n",
    "liste = ['Baden-Württemberg','Bayern','Berlin','Brandenburg','Bremen','Hamburg','Hessen','Mecklenburg-Vorpommern','Niedersachsen','Nordrhein-Westfalen','Rheinland-Pfalz','Saarland','Sachsen','Sachsen-Anhalt','Schleswig-Holstein','Thüringen']\n",
    "\n",
    "for i, row in durchwachstumfnl.iterrows():\n",
    "        durchwachstumfnl.at[i,'Bundesland'] = liste[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dichte = pd.read_excel('A_BevDichte_Kreise.xlsx')\n",
    "dichte = dichte.drop(columns = ['Kennziffer','Thünen-Typ'])\n",
    "dichte = dichte.sort_values(by=['Name'])\n",
    "dichte = dichte.reset_index()\n",
    "dichte = dichte.drop(columns = 'index')\n",
    "\n",
    "#Wird genutzt um die Stadt von dem Landkreis zu trennen\n",
    "name = ' Stadt'\n",
    "\n",
    "for j in range(len(dichte)):\n",
    "    if j == 401:\n",
    "        break\n",
    "    else:\n",
    "        if dichte['Name'][j] == dichte['Name'][j+1]:\n",
    "            if dichte['Bevölkerungsdichte 2014'][j] > dichte['Bevölkerungsdichte 2014'][j+1]:\n",
    "                dichte['Name'][j+1] = dichte['Name'][j+1] + name\n",
    "            else:\n",
    "                dichte['Name'][j] = dichte['Name'][j] + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dichteU = pd.DataFrame(columns= ['Landkreis/Kreis','Bev.D.Ew./km²'])\n",
    "dichteU['Landkreis/Kreis'] = arraykreise\n",
    "dichteU = dichteU.fillna(0)\n",
    "\n",
    "for i in range(len(dichte)):\n",
    "    for j in range(len(arraykreise)):\n",
    "        if arraykreise[j] == dichte['Name'][i]:\n",
    "            dichteU['Bev.D.Ew./km²'][j] = dichte['Bevölkerungsdichte 2014'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {'Landkreise/Kreis':arraykreise,'AGR':durchschnittlicheswachstum}\n",
    "compLK = pd.DataFrame(t) #compLK = Vergleich der Landkreise von Wachstum und Bevölkerungsdichte\n",
    "compLK['AGR_D'] = durchschnittlicheswachstumD\n",
    "compLK['Bev.D.Ew./km²'] = dichteU['Bev.D.Ew./km²'].astype(float)\n",
    "compLK = compLK.fillna(0)\n",
    "compLK = compLK.loc[compLK['Bev.D.Ew./km²'] != 0.0]\n",
    "compLK = compLK.loc[compLK['AGR'] != 0.0]\n",
    "compLK = compLK.loc[compLK['AGR_D'] != 0.0]\n",
    "#Sonst geht Clustering nicht\n",
    "compLKfnl = compLK.drop(columns =['Landkreise/Kreis'])\n",
    "compLKfnl = compLKfnl.rename(columns={'Bev.D.Ew./km²':'Dichte'})\n",
    "compLKfnl = compLKfnl.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCounty = DFCounty.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
